# Binary WebSocket Protocol Examples

This guide demonstrates how to work with Developer Mesh's high-performance binary WebSocket protocol.

## Overview

The binary WebSocket protocol provides:
- **âš¡ 70% bandwidth reduction** compared to JSON
- **ðŸ—œï¸ Automatic compression** for messages >1KB
- **ðŸ”„ Mixed text/binary support** in the same connection
- **ðŸ“Š Header-based versioning** for backward compatibility

## Protocol Structure

### Message Format
```
+--------+--------+--------+--------+
| Version|  Type  | Flags  | Length |  4 bytes (header)
+--------+--------+--------+--------+
|          Message Payload          |  Variable length
+-----------------------------------+
```

## Enabling Binary Protocol

To enable binary protocol on your WebSocket connection, use the `protocol.set_binary` method:

```json
{
  "jsonrpc": "2.0",
  "method": "protocol.set_binary",
  "params": {
    "enabled": true,
    "compression": {
      "enabled": true,
      "threshold": 1024
    }
  },
  "id": "1"
}
```

**Important**: The correct method name is `protocol.set_binary`, not `set_binary_protocol`.

## Client Implementation Examples

### 1. JavaScript/TypeScript Client

```typescript
import { MCPBinaryClient } from '@developer-mesh/client';

class BinaryWebSocketExample {
  private client: MCPBinaryClient;
  
  constructor(url: string, apiKey: string) {
    this.client = new MCPBinaryClient({
      url,
      apiKey,
      protocol: 'binary',
      compression: true,
      compressionThreshold: 1024 // Compress messages >1KB
    });
    
    // Set up event handlers
    this.setupHandlers();
  }
  
  async connect() {
    await this.client.connect();
    
    // Enable binary protocol after connection
    await this.client.send({
      jsonrpc: "2.0",
      method: "protocol.set_binary",
      params: {
        enabled: true,
        compression: {
          enabled: true,
          threshold: 1024
        }
      },
      id: "1"
    });
  }
  
  private setupHandlers() {
    // Handle binary messages
    this.client.onBinary((data: ArrayBuffer) => {
      const view = new DataView(data);
      
      // Parse header
      const header = this.parseHeader(view);
      
      // Process based on message type
      switch (header.type) {
        case MessageType.EMBEDDING:
          this.handleEmbedding(data, header);
          break;
        case MessageType.AGENT_STATE:
          this.handleAgentState(data, header);
          break;
        case MessageType.METRICS:
          this.handleMetrics(data, header);
          break;
      }
    });
    
    // Handle text messages (still supported)
    this.client.onText((message: string) => {
      const data = JSON.parse(message);
      console.log('Received text message:', data);
    });
  }
  
  private parseHeader(view: DataView): MessageHeader {
    return {
      version: view.getUint8(0),
      type: view.getUint8(1),
      flags: view.getUint8(2),
      length: view.getUint8(3)
    };
  }
  
  // Send binary embedding data
  async sendEmbedding(
    agentId: string, 
    embedding: Float32Array,
    metadata: any
  ) {
    // Create binary message
    const buffer = new ArrayBuffer(
      4 + // header
      36 + // UUID (agent ID)
      4 + embedding.length * 4 + // embedding data
      JSON.stringify(metadata).length
    );
    
    const view = new DataView(buffer);
    
    // Write header
    view.setUint8(0, 1); // version
    view.setUint8(1, MessageType.EMBEDDING);
    view.setUint8(2, 0); // flags
    view.setUint8(3, buffer.byteLength);
    
    // Write agent ID (UUID as bytes)
    const agentIdBytes = this.uuidToBytes(agentId);
    agentIdBytes.forEach((byte, i) => {
      view.setUint8(4 + i, byte);
    });
    
    // Write embedding dimensions
    view.setUint32(40, embedding.length, true);
    
    // Write embedding data
    let offset = 44;
    embedding.forEach((value) => {
      view.setFloat32(offset, value, true);
      offset += 4;
    });
    
    // Write metadata as JSON at the end
    const metadataBytes = new TextEncoder().encode(
      JSON.stringify(metadata)
    );
    metadataBytes.forEach((byte, i) => {
      view.setUint8(offset + i, byte);
    });
    
    // Send binary message
    await this.client.sendBinary(buffer);
  }
  
  // Handle compressed agent state updates
  private handleAgentState(data: ArrayBuffer, header: MessageHeader) {
    // Check if compressed
    if (header.flags & Flags.COMPRESSED) {
      data = this.decompress(data);
    }
    
    const view = new DataView(data);
    let offset = 4; // Skip header
    
    // Read agent ID
    const agentId = this.bytesToUuid(data.slice(offset, offset + 36));
    offset += 36;
    
    // Read state
    const stateLength = view.getUint32(offset, true);
    offset += 4;
    
    const stateBytes = new Uint8Array(data, offset, stateLength);
    const state = new TextDecoder().decode(stateBytes);
    
    console.log(`Agent ${agentId} state update:`, JSON.parse(state));
  }
  
  // Efficient metrics streaming
  async streamMetrics(metrics: MetricsBatch) {
    const buffer = this.encodeMetrics(metrics);
    
    // Will be compressed automatically if >1KB
    await this.client.sendBinary(buffer);
  }
  
  private encodeMetrics(metrics: MetricsBatch): ArrayBuffer {
    // Calculate total size
    const size = 4 + // header
                 8 + // timestamp
                 4 + // metric count
                 metrics.data.length * 16; // each metric
    
    const buffer = new ArrayBuffer(size);
    const view = new DataView(buffer);
    
    // Header
    view.setUint8(0, 1); // version
    view.setUint8(1, MessageType.METRICS);
    view.setUint8(2, 0); // flags
    view.setUint8(3, size);
    
    // Timestamp
    view.setBigUint64(4, BigInt(metrics.timestamp), true);
    
    // Metric count
    view.setUint32(12, metrics.data.length, true);
    
    // Metrics data
    let offset = 16;
    metrics.data.forEach(metric => {
      view.setUint32(offset, metric.id, true);
      view.setFloat32(offset + 4, metric.value, true);
      view.setUint32(offset + 8, metric.labels, true);
      view.setUint32(offset + 12, metric.flags, true);
      offset += 16;
    });
    
    return buffer;
  }
}

// Usage example
async function main() {
  const client = new BinaryWebSocketExample(
    'wss://api.developer-mesh.com/ws',
    'your-api-key'
  );
  
  await client.connect();
  
  // Send embedding efficiently
  const embedding = new Float32Array(1536); // Example embedding
  await client.sendEmbedding(
    'agent-123',
    embedding,
    { model: 'ada-002', context: 'code-review' }
  );
  
  // Stream metrics
  await client.streamMetrics({
    timestamp: Date.now(),
    data: [
      { id: 1, value: 0.95, labels: 0x01, flags: 0 },
      { id: 2, value: 42.5, labels: 0x02, flags: 0 },
      { id: 3, value: 128, labels: 0x04, flags: 0 }
    ]
  });
}
```

### 2. Go Client Example

```go
package main

import (
    "bytes"
    "encoding/binary"
    "encoding/json"
    "fmt"
    "github.com/gorilla/websocket"
    "github.com/klauspost/compress/zstd"
)

type BinaryClient struct {
    conn       *websocket.Conn
    compressor *zstd.Encoder
}

// Message types
const (
    TypeText      = 0x01
    TypeEmbedding = 0x02
    TypeAgentState = 0x03
    TypeMetrics   = 0x04
)

// Flags
const (
    FlagCompressed = 0x01
    FlagPriority   = 0x02
)

type Header struct {
    Version uint8
    Type    uint8
    Flags   uint8
    Length  uint8
}

func NewBinaryClient(url string) (*BinaryClient, error) {
    conn, _, err := websocket.DefaultDialer.Dial(url, nil)
    if err != nil {
        return nil, err
    }
    
    encoder, _ := zstd.NewWriter(nil)
    
    return &BinaryClient{
        conn:       conn,
        compressor: encoder,
    }, nil
}

// Send binary embedding
func (c *BinaryClient) SendEmbedding(
    agentID string,
    embedding []float32,
    metadata map[string]interface{},
) error {
    buf := new(bytes.Buffer)
    
    // Write header
    header := Header{
        Version: 1,
        Type:    TypeEmbedding,
        Flags:   0,
        Length:  0, // Will calculate
    }
    binary.Write(buf, binary.LittleEndian, header)
    
    // Write agent ID (as bytes)
    agentBytes, _ := parseUUID(agentID)
    buf.Write(agentBytes)
    
    // Write embedding dimensions
    binary.Write(buf, binary.LittleEndian, uint32(len(embedding)))
    
    // Write embedding data
    for _, val := range embedding {
        binary.Write(buf, binary.LittleEndian, val)
    }
    
    // Write metadata
    metaJSON, _ := json.Marshal(metadata)
    buf.Write(metaJSON)
    
    // Check if we should compress
    data := buf.Bytes()
    if len(data) > 1024 {
        compressed := c.compressor.EncodeAll(data[4:], nil)
        
        // Update header with compressed flag
        data[2] |= FlagCompressed
        
        // Replace data with compressed version
        newBuf := bytes.NewBuffer(data[:4])
        newBuf.Write(compressed)
        data = newBuf.Bytes()
    }
    
    // Send binary message
    return c.conn.WriteMessage(websocket.BinaryMessage, data)
}

// Efficient batch operations
func (c *BinaryClient) SendBatch(operations []Operation) error {
    buf := new(bytes.Buffer)
    
    // Batch header
    binary.Write(buf, binary.LittleEndian, uint32(len(operations)))
    
    // Write each operation
    for _, op := range operations {
        c.encodeOperation(buf, op)
    }
    
    // Always compress batches
    compressed := c.compressor.EncodeAll(buf.Bytes(), nil)
    
    // Create final message with compression flag
    finalBuf := new(bytes.Buffer)
    header := Header{
        Version: 1,
        Type:    TypeBatch,
        Flags:   FlagCompressed,
        Length:  uint8(len(compressed)),
    }
    binary.Write(finalBuf, binary.LittleEndian, header)
    finalBuf.Write(compressed)
    
    return c.conn.WriteMessage(websocket.BinaryMessage, finalBuf.Bytes())
}

// High-frequency metrics streaming
func (c *BinaryClient) StreamMetrics(ch <-chan Metric) {
    ticker := time.NewTicker(100 * time.Millisecond)
    batch := make([]Metric, 0, 100)
    
    for {
        select {
        case metric := <-ch:
            batch = append(batch, metric)
            
            // Send if batch is full
            if len(batch) >= 100 {
                c.sendMetricsBatch(batch)
                batch = batch[:0]
            }
            
        case <-ticker.C:
            // Send whatever we have
            if len(batch) > 0 {
                c.sendMetricsBatch(batch)
                batch = batch[:0]
            }
        }
    }
}

func (c *BinaryClient) sendMetricsBatch(metrics []Metric) error {
    buf := new(bytes.Buffer)
    
    // Header
    header := Header{
        Version: 1,
        Type:    TypeMetrics,
        Flags:   0,
        Length:  0,
    }
    binary.Write(buf, binary.LittleEndian, header)
    
    // Timestamp
    binary.Write(buf, binary.LittleEndian, time.Now().UnixNano())
    
    // Metric count
    binary.Write(buf, binary.LittleEndian, uint32(len(metrics)))
    
    // Metrics data (compact binary format)
    for _, m := range metrics {
        binary.Write(buf, binary.LittleEndian, m.ID)
        binary.Write(buf, binary.LittleEndian, m.Value)
        binary.Write(buf, binary.LittleEndian, m.Labels)
        binary.Write(buf, binary.LittleEndian, m.Flags)
    }
    
    return c.conn.WriteMessage(websocket.BinaryMessage, buf.Bytes())
}
```

### 3. Python Client Example

```python
import struct
import asyncio
import websockets
import zstandard as zstd
import numpy as np
from typing import Dict, Any, List
from dataclasses import dataclass
from enum import IntEnum

class MessageType(IntEnum):
    TEXT = 0x01
    EMBEDDING = 0x02
    AGENT_STATE = 0x03
    METRICS = 0x04
    BATCH = 0x05

class Flags(IntEnum):
    COMPRESSED = 0x01
    PRIORITY = 0x02

@dataclass
class Header:
    version: int
    type: MessageType
    flags: int
    length: int
    
    def pack(self) -> bytes:
        return struct.pack('<BBBB', self.version, self.type, self.flags, self.length)
    
    @classmethod
    def unpack(cls, data: bytes) -> 'Header':
        version, msg_type, flags, length = struct.unpack('<BBBB', data[:4])
        return cls(version, MessageType(msg_type), flags, length)

class BinaryWebSocketClient:
    def __init__(self, url: str, api_key: str):
        self.url = url
        self.api_key = api_key
        self.ws = None
        self.compressor = zstd.ZstdCompressor()
        self.decompressor = zstd.ZstdDecompressor()
    
    async def connect(self):
        headers = {"Authorization": f"Bearer {self.api_key}"}
        self.ws = await websockets.connect(self.url, extra_headers=headers)
        
        # Start message handler
        asyncio.create_task(self._handle_messages())
    
    async def _handle_messages(self):
        async for message in self.ws:
            if isinstance(message, bytes):
                await self._handle_binary(message)
            else:
                await self._handle_text(message)
    
    async def _handle_binary(self, data: bytes):
        header = Header.unpack(data)
        
        # Extract payload
        payload = data[4:]
        
        # Decompress if needed
        if header.flags & Flags.COMPRESSED:
            payload = self.decompressor.decompress(payload)
        
        # Route to handler
        if header.type == MessageType.EMBEDDING:
            await self._handle_embedding(payload)
        elif header.type == MessageType.METRICS:
            await self._handle_metrics(payload)
    
    async def send_embedding(
        self,
        agent_id: str,
        embedding: np.ndarray,
        metadata: Dict[str, Any]
    ):
        """Send embedding as binary data"""
        # Convert embedding to bytes
        embedding_bytes = embedding.astype(np.float32).tobytes()
        
        # Build message
        message = bytearray()
        
        # Add header (placeholder)
        message.extend(b'\x00\x00\x00\x00')
        
        # Add agent ID (36 bytes for UUID)
        agent_uuid = uuid.UUID(agent_id).bytes
        message.extend(agent_uuid)
        
        # Add embedding dimensions
        message.extend(struct.pack('<I', len(embedding)))
        
        # Add embedding data
        message.extend(embedding_bytes)
        
        # Add metadata as JSON
        metadata_json = json.dumps(metadata).encode()
        message.extend(metadata_json)
        
        # Check if compression needed
        if len(message) > 1024:
            payload = self.compressor.compress(message[4:])
            flags = Flags.COMPRESSED
        else:
            payload = message[4:]
            flags = 0
        
        # Update header
        header = Header(
            version=1,
            type=MessageType.EMBEDDING,
            flags=flags,
            length=len(payload)
        )
        message[:4] = header.pack()
        
        # Send
        final_message = header.pack() + payload
        await self.ws.send(final_message)
    
    async def stream_metrics(self, metrics_stream):
        """Stream metrics efficiently in batches"""
        batch = []
        batch_size = 0
        max_batch_size = 100
        max_batch_bytes = 4096
        
        async for metric in metrics_stream:
            batch.append(metric)
            batch_size += 16  # Each metric is 16 bytes
            
            # Send batch if it's full or large enough
            if len(batch) >= max_batch_size or batch_size >= max_batch_bytes:
                await self._send_metrics_batch(batch)
                batch = []
                batch_size = 0
        
        # Send remaining metrics
        if batch:
            await self._send_metrics_batch(batch)
    
    async def _send_metrics_batch(self, metrics: List[Dict]):
        """Send a batch of metrics as binary"""
        message = bytearray()
        
        # Header placeholder
        message.extend(b'\x00\x00\x00\x00')
        
        # Timestamp
        message.extend(struct.pack('<Q', int(time.time() * 1e9)))
        
        # Metric count
        message.extend(struct.pack('<I', len(metrics)))
        
        # Pack metrics efficiently
        for metric in metrics:
            message.extend(struct.pack('<I', metric['id']))
            message.extend(struct.pack('<f', metric['value']))
            message.extend(struct.pack('<I', metric['labels']))
            message.extend(struct.pack('<I', metric.get('flags', 0)))
        
        # Always compress metrics batches
        payload = self.compressor.compress(message[4:])
        
        # Create header
        header = Header(
            version=1,
            type=MessageType.METRICS,
            flags=Flags.COMPRESSED,
            length=len(payload)
        )
        
        # Send
        await self.ws.send(header.pack() + payload)

# Example usage
async def example_usage():
    client = BinaryWebSocketClient(
        "wss://api.developer-mesh.com/ws",
        "your-api-key"
    )
    
    await client.connect()
    
    # Send high-dimensional embedding
    embedding = np.random.randn(1536)  # Example embedding
    await client.send_embedding(
        agent_id="agent-123",
        embedding=embedding,
        metadata={
            "model": "text-embedding-ada-002",
            "context": "code-analysis",
            "timestamp": time.time()
        }
    )
    
    # Stream metrics efficiently
    async def generate_metrics():
        metric_id = 0
        while True:
            yield {
                "id": metric_id,
                "value": np.random.random() * 100,
                "labels": 0x01,
                "flags": 0
            }
            metric_id += 1
            await asyncio.sleep(0.01)  # 100 metrics/second
    
    # This will batch and compress automatically
    await client.stream_metrics(generate_metrics())
```

## Performance Benchmarks

### Bandwidth Savings
```python
# JSON vs Binary comparison
json_message = {
    "agent_id": "123e4567-e89b-12d3-a456-426614174000",
    "embedding": [0.1234567] * 1536,  # 1536-dimensional
    "metadata": {"model": "ada-002", "timestamp": 1234567890}
}

# JSON size: ~15KB
# Binary size: ~6KB (60% smaller)
# Compressed binary: ~2KB (87% smaller)
```

### Latency Improvements
```
Message Type     | JSON    | Binary  | Binary+Compression
-----------------|---------|---------|-------------------
Small (<1KB)     | 2.1ms   | 0.8ms   | 0.9ms
Medium (10KB)    | 15.3ms  | 6.2ms   | 4.1ms
Large (100KB)    | 142ms   | 58ms    | 21ms
```

## Best Practices

### 1. Message Batching
```typescript
// Batch multiple operations for efficiency
const batch = new MessageBatch();

for (const operation of operations) {
    batch.add(operation);
    
    // Send when batch is full or timeout
    if (batch.size() >= 100 || batch.age() > 100) {
        await client.sendBatch(batch);
        batch.clear();
    }
}
```

### 2. Selective Compression
```go
// Only compress large messages
func shouldCompress(data []byte) bool {
    return len(data) > 1024 && !isAlreadyCompressed(data)
}
```

### 3. Connection Pooling
```python
class BinaryConnectionPool:
    def __init__(self, url: str, pool_size: int = 5):
        self.connections = [
            BinaryWebSocketClient(url) for _ in range(pool_size)
        ]
        self.current = 0
    
    def get_connection(self) -> BinaryWebSocketClient:
        conn = self.connections[self.current]
        self.current = (self.current + 1) % len(self.connections)
        return conn
```

## Error Handling

```typescript
client.on('error', (error) => {
    if (error.code === 'COMPRESSION_FAILED') {
        // Fall back to uncompressed
        client.send(data, { compress: false });
    } else if (error.code === 'INVALID_MESSAGE_TYPE') {
        // Log and skip
        console.error('Unknown message type:', error.messageType);
    }
});
```

## Monitoring Binary Protocol

```go
// Metrics to track
var (
    messagesCompressed = prometheus.NewCounter(
        prometheus.CounterOpts{
            Name: "websocket_messages_compressed_total",
        },
    )
    compressionRatio = prometheus.NewHistogram(
        prometheus.HistogramOpts{
            Name: "websocket_compression_ratio",
            Buckets: []float64{0.1, 0.3, 0.5, 0.7, 0.9},
        },
    )
    messageSizeBytes = prometheus.NewHistogram(
        prometheus.HistogramOpts{
            Name: "websocket_message_size_bytes",
            Buckets: prometheus.ExponentialBuckets(100, 2, 10),
        },
    )
)
```

## Next Steps

1. **Explore CRDT Collaboration**: See [crdt-collaboration-examples.md](crdt-collaboration-examples.md)
2. **WebSocket API Reference**: Check [agent-websocket-protocol.md](../guides/agent-websocket-protocol.md)
3. **Performance Tuning**: Read [performance-tuning-guide.md](../guides/performance-tuning-guide.md)

---

*For more examples and support, visit our [GitHub repository](https://github.com/S-Corkum/developer-mesh)*